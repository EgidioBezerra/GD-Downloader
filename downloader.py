# downloader.py - Refatorado com Playwright e t√©cnicas modernas (2025)
import asyncio
import io
import os
import time
import logging
import json
from pathlib import Path
from typing import Optional, List, Dict
from functools import wraps

try:
    import pyautogui
    PYAUTOGUI_AVAILABLE = True
except ImportError:
    PYAUTOGUI_AVAILABLE = False
    logging.warning("PyAutoGUI n√£o dispon√≠vel. Instale: pip install pyautogui")

from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from googleapiclient.errors import HttpError
from tqdm import tqdm

# Playwright para automa√ß√£o moderna (recomendado)
try:
    from playwright.async_api import async_playwright, Page, Browser
    PLAYWRIGHT_AVAILABLE = True
    
    # Tenta importar stealth (opcional - apenas async)
    try:
        from playwright_stealth import stealth_async
        STEALTH_AVAILABLE = True
    except ImportError:
        STEALTH_AVAILABLE = False
        logging.info("playwright-stealth n√£o dispon√≠vel - usando stealth nativo")
            
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    STEALTH_AVAILABLE = False
    logging.warning("Playwright n√£o dispon√≠vel. Instale: pip install playwright")

# Fallback para Selenium (compatibilidade)
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options as ChromeOptions
    from selenium.webdriver.common.keys import Keys
    from webdriver_manager.chrome import ChromeDriverManager
    from PIL import Image
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    logging.warning("Selenium n√£o dispon√≠vel. PDFs view-only n√£o funcionar√£o sem Playwright.")


# ============================================================================
# DECORADORES E UTILIDADES
# ============================================================================

def retry_on_failure(max_attempts: int = 3, delay: int = 2, exponential_backoff: bool = True):
    """Decorator para retry autom√°tico com exponential backoff."""
    def decorator(func):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise
                    wait_time = delay * (2 ** attempt) if exponential_backoff else delay
                    logging.warning(f"Tentativa {attempt + 1}/{max_attempts} falhou: {e}. "
                                  f"Aguardando {wait_time}s...")
                    await asyncio.sleep(wait_time)
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise
                    wait_time = delay * (2 ** attempt) if exponential_backoff else delay
                    logging.warning(f"Tentativa {attempt + 1}/{max_attempts} falhou: {e}. "
                                  f"Aguardando {wait_time}s...")
                    time.sleep(wait_time)
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator


# ============================================================================
# DOWNLOAD DE ARQUIVOS PADR√ÉO
# ============================================================================

@retry_on_failure(max_attempts=5, delay=2)
def download_standard_file(service, file_id: str, save_path: str) -> bool:
    """Download de arquivos padr√£o com retry autom√°tico."""
    file_name = os.path.basename(save_path)
    
    try:
        request = service.files().get_media(fileId=file_id)
        file_metadata = service.files().get(fileId=file_id, fields='size').execute()
        total_size = int(file_metadata.get('size', 0))

        with open(save_path, 'wb') as f:
            with tqdm(
                total=total_size, unit='B', unit_scale=True,
                unit_divisor=1024, desc=f" {file_name}", leave=False
            ) as pbar:
                downloader = MediaIoBaseDownload(f, request, chunksize=1024*1024)
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                    if status:
                        pbar.update(status.resumable_progress - pbar.n)
        
        logging.info(f"‚úì SUCESSO (Download Padr√£o): '{file_name}' ‚Üí '{save_path}'")
        return True
    
    except HttpError as e:
        if hasattr(e, 'error_details') and e.error_details:
            if any(d.get('reason') == 'fileNotDownloadable' for d in e.error_details):
                logging.error(f"‚úó Erro 403: arquivo '{file_name}' n√£o pode ser baixado (view-only)")
                return False
        raise
    except Exception as e:
        logging.error(f"‚úó Erro no download de '{file_name}': {e}")
        raise


# ============================================================================
# EXPORTA√á√ÉO DE GOOGLE DOCS
# ============================================================================

@retry_on_failure(max_attempts=3, delay=2)
def export_google_doc(service, file_id: str, save_path: str) -> bool:
    """Exporta Google Docs como PDF."""
    file_name = os.path.basename(save_path)
    base_name, _ = os.path.splitext(save_path)
    pdf_save_path = f"{base_name}.pdf"

    try:
        request = service.files().export_media(fileId=file_id, mimeType='application/pdf')
        
        with open(pdf_save_path, 'wb') as f:
            with tqdm(
                unit='B', unit_scale=True, unit_divisor=1024, 
                desc=f" (Exportando) {os.path.basename(pdf_save_path)}", leave=False
            ) as pbar:
                downloader = MediaIoBaseDownload(f, request)
                done = False
                while not done:
                    status, done = downloader.next_chunk()
                    if status:
                        pbar.update(status.resumable_progress - pbar.n)

        logging.info(f"‚úì SUCESSO (Exporta√ß√£o): '{file_name}' ‚Üí '{pdf_save_path}'")
        return True
    
    except Exception as e:
        logging.error(f"‚úó Erro ao exportar '{file_name}': {e}")
        raise


# ============================================================================
# DOWNLOAD DE V√çDEOS VIEW-ONLY
# ============================================================================

@retry_on_failure(max_attempts=3, delay=5)
def download_view_only_video(creds, file_id: str, file_name: str, save_path: str, 
                            debug_html: bool = False, hwaccel: Optional[str] = None, 
                            encoder: Optional[str] = None) -> bool:
    """Baixa v√≠deos view-only usando m√©todo otimizado."""
    try:
        import requests
        from urllib.parse import unquote
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        
        logging.info(f"Iniciando download de v√≠deo view-only: {file_name}")
        
        session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=0.5,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=10,
            pool_maxsize=10,
            pool_block=False
        )
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        drive_url = f'https://drive.google.com/u/0/get_video_info?docid={file_id}&drive_originator_app=303'
        response = session.get(drive_url, timeout=30)
        
        if response.status_code != 200:
            raise Exception(f"Falha ao acessar API: status {response.status_code}")
        
        page_content = response.text
        cookies = response.cookies.get_dict()
        
        content_list = page_content.split("&")
        video_url = None
        video_title = None
        
        for content in content_list:
            if content.startswith('title=') and not video_title:
                video_title = unquote(content.split('=')[-1])
            elif "videoplayback" in content and not video_url:
                video_url = unquote(content).split("|")[-1]
            if video_url and video_title:
                break
        
        if not video_url:
            raise Exception("N√£o foi poss√≠vel extrair URL do v√≠deo")
        
        head_response = session.head(video_url, cookies=cookies, timeout=10)
        total_size = int(head_response.headers.get('content-length', 0))
        
        headers = {}
        file_mode = 'wb'
        downloaded_size = 0
        
        if os.path.exists(save_path):
            downloaded_size = os.path.getsize(save_path)
            if downloaded_size < total_size:
                headers['Range'] = f"bytes={downloaded_size}-"
                file_mode = 'ab'
                logging.info(f"Resumindo download do byte {downloaded_size}")
            else:
                logging.info(f"Arquivo j√° completo")
                return True
        
        response = session.get(
            video_url, 
            stream=True, 
            cookies=cookies, 
            headers=headers,
            timeout=60
        )
        
        if response.status_code not in (200, 206):
            raise Exception(f"Erro no download: status {response.status_code}")
        
        if response.status_code == 206:
            total_size = int(response.headers.get('content-length', 0)) + downloaded_size
        
        chunk_size = 5 * 1024 * 1024  # 5MB
        
        with open(save_path, file_mode) as file:
            with tqdm(
                total=total_size,
                initial=downloaded_size,
                unit='B',
                unit_scale=True,
                desc=f" {file_name}",
                leave=False
            ) as pbar:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        file.write(chunk)
                        pbar.update(len(chunk))
        
        if os.path.exists(save_path):
            file_size = os.path.getsize(save_path)
            if file_size > 1024:
                logging.info(f"‚úì SUCESSO (V√≠deo View-Only): '{file_name}' ({file_size / 1024 / 1024:.2f} MB)")
                return True
            else:
                os.remove(save_path)
                raise Exception(f"Arquivo muito pequeno: {file_size} bytes")
        
        raise Exception("Arquivo n√£o foi criado")
    
    except Exception as e:
        logging.error(f"‚úó FALHA (V√≠deo View-Only) '{file_name}': {type(e).__name__}: {e}")
        raise


# ============================================================================
# DOWNLOAD DE PDFs VIEW-ONLY COM PLAYWRIGHT (M√âTODO PRINCIPAL)
# ============================================================================

async def download_view_only_pdf_playwright(service, file_id: str, save_path: str, 
                                           temp_download_dir: str) -> bool:
    """
    Download de PDFs view-only usando Playwright com t√©cnicas modernas de 2025.
    M√©todo principal: canvas-based blob extraction com stealth avan√ßado.
    """
    if not PLAYWRIGHT_AVAILABLE:
        logging.error("Playwright n√£o dispon√≠vel. Instale com: pip install playwright playwright-stealth")
        return False
    
    file_name = os.path.basename(save_path)
    
    try:
        logging.info(f"üöÄ Iniciando download Playwright: {file_name}")
        print(f"  üìÑ Processando: {file_name[:60]}...")
        
        # Obter URL do arquivo
        file_metadata = service.files().get(fileId=file_id, fields='webViewLink').execute()
        view_url = file_metadata.get('webViewLink')
        if not view_url:
            raise Exception("URL de visualiza√ß√£o n√£o dispon√≠vel")
        
        async with async_playwright() as p:
            browser = await _launch_stealth_browser(p)
            page = await _create_stealth_page(browser)
            
            try:
                # Navegar para o PDF
                await page.goto(view_url, wait_until='networkidle', timeout=60000)
                print("    ‚è≥ Aguardando carregamento inicial...")
                await asyncio.sleep(8)
                
                # Detectar n√∫mero total de p√°ginas
                total_pages = await _detect_total_pages(page)
                if total_pages == 0:
                    raise Exception("N√£o foi poss√≠vel detectar p√°ginas do documento")
                
                print(f"    üìä Documento tem {total_pages} p√°ginas")
                
                # For√ßar carregamento completo via scroll inteligente
                await _intelligent_scroll_load(page, total_pages)
                
                # Aplicar zoom para melhor qualidade
                await page.evaluate("document.body.style.zoom = '2.0';")
                await asyncio.sleep(2)
                
                # Extrair blobs via canvas
                pdf_data, actual_pages = await _extract_blobs_to_pdf(page, file_name)
                
                # Salvar PDF
                with open(save_path, 'wb') as f:
                    f.write(pdf_data)
                
                file_size = os.path.getsize(save_path)
                print(f"    ‚úì Completo: {file_size / 1024 / 1024:.2f} MB ({actual_pages} p√°ginas)")
                logging.info(f"‚úì SUCESSO (PDF View-Only): '{file_name}' ({actual_pages} p√°ginas)")
                
                return True
            
            finally:
                await browser.close()
    
    except Exception as e:
        logging.error(f"‚úó FALHA (PDF View-Only) '{file_name}': {type(e).__name__}: {e}")
        print(f"    ‚úó Erro: {type(e).__name__}")
        return False


async def _launch_stealth_browser(playwright) -> Browser:
    """Lan√ßa browser com configura√ß√µes stealth otimizadas."""
    # Argumentos base multiplataforma
    args = [
        '--disable-blink-features=AutomationControlled',
        '--disable-features=IsolateOrigins,site-per-process',
        '--window-size=1920,1080',
        '--disable-infobars',
        '--disable-extensions',
    ]
    
    # Argumentos espec√≠ficos por plataforma
    if os.name != 'nt':  # Linux/Mac
        args.extend([
            '--no-sandbox',
            '--disable-dev-shm-usage',
        ])
    else:  # Windows
        args.extend([
            '--disable-gpu',  # Previne problemas GPU no Windows
        ])
    
    return await playwright.chromium.launch(
        headless=False,  # Modo vis√≠vel √© mais stealth
        args=args
    )


async def _create_stealth_page(browser: Browser) -> Page:
    """Cria p√°gina com contexto stealth completo."""
    context = await browser.new_context(
        viewport={'width': 1920, 'height': 1080},
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        locale='en-US',
        timezone_id='America/New_York',
        extra_http_headers={
            'Accept-Language': 'en-US,en;q=0.9',
        }
    )
    
    page = await context.new_page()
    
    # Aplica stealth se dispon√≠vel
    if STEALTH_AVAILABLE == True:
        try:
            await stealth_async(page)
            logging.info("Stealth plugin aplicado")
        except Exception as e:
            logging.warning(f"Erro ao aplicar stealth plugin: {e}")
    elif STEALTH_AVAILABLE == "sync":
        try:
            # Vers√£o sync do stealth
            import asyncio
            await asyncio.get_event_loop().run_in_executor(None, stealth, page)
            logging.info("Stealth plugin (sync) aplicado")
        except Exception as e:
            logging.warning(f"Erro ao aplicar stealth sync: {e}")
    
    # Scripts anti-detec√ß√£o nativos (sempre aplica)
    await page.add_init_script("""
        // Remove webdriver flag
        Object.defineProperty(navigator, 'webdriver', {
            get: () => false
        });
        
        // Simula plugins
        Object.defineProperty(navigator, 'plugins', {
            get: () => [1, 2, 3, 4, 5]
        });
        
        // Chrome runtime
        window.chrome = {
            runtime: {}
        };
        
        // Permissions
        const originalQuery = window.navigator.permissions.query;
        window.navigator.permissions.query = (parameters) => (
            parameters.name === 'notifications' ?
                Promise.resolve({ state: Notification.permission }) :
                originalQuery(parameters)
        );
        
        // Languages
        Object.defineProperty(navigator, 'languages', {
            get: () => ['en-US', 'en']
        });
    """)
    
    logging.info("Scripts anti-detec√ß√£o nativos aplicados")
    
    return page


async def _detect_total_pages(page: Page) -> int:
    """Detecta n√∫mero total de p√°ginas - vers√£o mais robusta."""
    
    await asyncio.sleep(3)  # Aguarda p√°gina carregar completamente
    
    # Estrat√©gia 1: Busca AGRESSIVA por indicador de p√°ginas
    total_from_ui = await page.evaluate("""() => {
        // Busca em todos os textos da p√°gina
        const allText = document.body.innerText;
        
        // Padr√µes: "de 9", "of 9", "/ 9", "Page 1 of 9"
        const patterns = [
            /(?:de|of)\\s+(\\d+)/gi,
            /\\/\\s*(\\d+)/g,
            /Page\\s+\\d+\\s+of\\s+(\\d+)/gi,
            /(\\d+)\\s+(?:pages|p√°ginas)/gi
        ];
        
        let maxPages = 0;
        for (let pattern of patterns) {
            const matches = allText.matchAll(pattern);
            for (let match of matches) {
                const num = parseInt(match[1]);
                if (num > maxPages && num < 1000) {  // Sanity check
                    maxPages = num;
                }
            }
        }
        
        return maxPages;
    }""")
    
    if total_from_ui > 0:
        print(f"    üìä Documento tem {total_from_ui} p√°ginas (detectado)")
        return total_from_ui
    
    # Estrat√©gia 2: Conta p√°ginas atualmente vis√≠veis (fallback)
    current_count = await page.evaluate("""() => {
        return document.querySelectorAll('img[src^="blob:"]').length;
    }""")
    
    # Se s√≥ detectou p√°ginas vis√≠veis, assume que tem mais
    if current_count > 0:
        print(f"    ‚ö† Detectadas apenas {current_count} p√°ginas vis√≠veis (pode ter mais)")
        return 0  # Retorna 0 para for√ßar scroll completo
    
    return 0


async def _intelligent_scroll_load(page: Page, expected_pages: int):
    """Scroll com PyAutoGUI (controle real do mouse do sistema operacional)."""
    
    if not PYAUTOGUI_AVAILABLE:
        print("    ‚ö† PyAutoGUI n√£o dispon√≠vel - instale: pip install pyautogui")
        return
    
    print("    üñ±Ô∏è Scroll PyAutoGUI (otimizado)")
    print("    ‚ö† N√£o use mouse (~40s)")
    print("    ‚è±Ô∏è Preparando...")
    await asyncio.sleep(1)
    
    # Traz foco para a janela
    try:
        w, h = pyautogui.size()
        pyautogui.click(w // 2, h // 2)
        await asyncio.sleep(0.5)
    except Exception as e:
        logging.debug(f"Erro ao dar foco: {e}")
    
    print("    üîÑ Iniciando scroll (voc√™ ver√° o mouse se mexendo)...")
    
    loaded = 0
    last = 0
    
    # SCROLL M√ÅXIMA VELOCIDADE: 50 cliques + infinito
    stable_count = 0
    at_bottom_count = 0
    iteration = 0
    
    print("    üöÄ Modo: Velocidade m√°xima (50 cliques/scroll)")
    
    while True:  # Scroll infinito
        pyautogui.scroll(-50)  # 50 cliques (era 30 = +66% velocidade)
        iteration += 1
        
        # Verifica a cada 10 (era 15 = +50% frequ√™ncia)
        if iteration % 10 == 0:
            try:
                loaded = await page.evaluate("() => document.querySelectorAll('img[src^=\"blob:\"]').length")
                
                # Progresso a cada 50
                if iteration % 50 == 0:
                    print(f"    üìÑ {loaded} p√°ginas (scroll {iteration})...")
                
                # Verifica fim do documento
                at_bottom = await page.evaluate("""() => {
                    return (window.innerHeight + window.scrollY) >= 
                           (document.documentElement.scrollHeight - 100);
                }""")
                
                # Parada: 3 est√°veis + 2 no fim
                if loaded == last and loaded > 0:
                    stable_count += 1
                    if at_bottom:
                        at_bottom_count += 1
                    else:
                        at_bottom_count = 0
                    
                    if stable_count >= 3 and at_bottom_count >= 2 and iteration > 80:
                        print(f"    ‚úì Fim: {loaded} p√°ginas (iter {iteration})")
                        break
                else:
                    stable_count = 0
                    at_bottom_count = 0
                
                last = loaded
                
                # Limite seguran√ßa
                if iteration >= 5000:
                    print(f"    ‚ö† Limite (5000): {loaded} p√°ginas")
                    break
            except:
                pass
    
    print("    ‚è≥ Aguardando (2s)...")
    await asyncio.sleep(2)
    
    print("    ‚¨ÜÔ∏è Voltando ao topo...")
    pyautogui.press('home')
    await asyncio.sleep(1)
    
    # Re-scroll ULTRA R√ÅPIDO
    print("    üîÑ Re-scroll...")
    for i in range(80):  # 80 scrolls (era 100)
        pyautogui.scroll(-50)  # 50 cliques (era 30)
    
    await asyncio.sleep(0.5)  # 0.5s (era 1s)
    pyautogui.press('home')
    await asyncio.sleep(0.5)  # 0.5s (era 1s)
    
    try:
        final = await page.evaluate("""() => {
            const imgs = document.querySelectorAll('img[src^="blob:"]');
            const unique = new Set();
            imgs.forEach(img => {
                if (img.naturalHeight > 100) unique.add(img.src);
            });
            return unique.size;
        }""")
        print(f"    ‚úì TOTAL FINAL: {final} p√°ginas renderizadas")
    except Exception as e:
        print(f"    ‚ÑπÔ∏è √öltima contagem: {loaded} p√°ginas")


async def _extract_blobs_to_pdf(page: Page, file_name: str) -> tuple[bytes, int]:
    """Extrai blobs via canvas e converte para PDF com PIL (SEM jsPDF).
    
    Returns:
        tuple[bytes, int]: (PDF bytes, n√∫mero de p√°ginas)
    """
    print("    üé® Extraindo imagens das p√°ginas...")
    
    from PIL import Image
    import base64
    from io import BytesIO
    
    # Extrai blobs como data URLs via canvas
    data_urls = await page.evaluate("""async () => {
        const imgs = Array.from(document.getElementsByTagName('img'));
        const blobs = imgs.filter(img => 
            img.src && img.src.startsWith('blob:') && img.naturalHeight > 100
        );
        
        // Remove duplicatas e ordena
        const unique = new Map();
        blobs.forEach(img => {
            if (!unique.has(img.src)) {
                const rect = img.getBoundingClientRect();
                unique.set(img.src, window.scrollY + rect.top);
            }
        });
        
        const sorted = Array.from(unique.entries()).sort((a, b) => a[1] - b[1]);
        
        // Converte cada blob para data URL via canvas
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        const results = [];
        
        for (let [src, _] of sorted) {
            const img = blobs.find(i => i.src === src);
            if (img) {
                canvas.width = img.naturalWidth;
                canvas.height = img.naturalHeight;
                ctx.drawImage(img, 0, 0);
                results.push(canvas.toDataURL('image/png'));
            }
        }
        
        return results;
    }""")
    
    if not data_urls or len(data_urls) == 0:
        raise Exception('Nenhuma p√°gina encontrada para extrair')
    
    print(f"    üìÑ Convertendo {len(data_urls)} p√°ginas para PDF...")
    
    # Converte data URLs para PIL Images (otimizado)
    pil_images = []
    for idx, data_url in enumerate(data_urls):
        try:
            img_b64 = data_url.split(',')[1]
            img_bytes = base64.b64decode(img_b64)
            pil_img = Image.open(BytesIO(img_bytes))
            
            # Converte para RGB se necess√°rio
            if pil_img.mode == 'RGBA':
                rgb_img = Image.new('RGB', pil_img.size, (255, 255, 255))
                rgb_img.paste(pil_img, mask=pil_img.split()[3])
                pil_img = rgb_img
            
            pil_images.append(pil_img)
            
            # Progresso a cada 5 p√°ginas (menos output = mais r√°pido)
            if (idx + 1) % 5 == 0 or (idx + 1) == len(data_urls):
                print(f"      ‚úì {idx + 1}/{len(data_urls)} p√°ginas")
        except Exception as e:
            logging.warning(f"Erro p√°gina {idx + 1}: {e}")
    
    if not pil_images:
        raise Exception('Falha ao converter imagens')
    
    # Cria PDF com PIL
    pdf_buf = BytesIO()
    if len(pil_images) == 1:
        pil_images[0].save(pdf_buf, 'PDF', resolution=100.0)
    else:
        pil_images[0].save(
            pdf_buf,
            'PDF',
            save_all=True,
            append_images=pil_images[1:],
            resolution=100.0
        )
    
    print(f"    ‚úì PDF criado com {len(pil_images)} p√°ginas")
    return (pdf_buf.getvalue(), len(pil_images))


# ============================================================================
# FALLBACK: DOWNLOAD COM SELENIUM (compatibilidade com c√≥digo existente)
# ============================================================================

def download_view_only_pdf_selenium(service, file_id: str, save_path: str, 
                                   temp_download_dir: str) -> bool:
    """
    Fallback usando Selenium (c√≥digo original mantido para compatibilidade).
    """
    if not SELENIUM_AVAILABLE:
        logging.error("Selenium n√£o dispon√≠vel e Playwright tamb√©m n√£o.")
        return False
    
    # Mant√©m implementa√ß√£o original do Selenium
    return _download_pdf_with_selenium_auto(service, file_id, os.path.basename(save_path), 
                                           save_path, temp_download_dir)


def _download_pdf_with_selenium_auto(service, file_id, file_name, save_path, temp_download_dir):
    """Implementa√ß√£o original Selenium mantida para compatibilidade."""
    driver = None
    
    try:
        logging.info(f"Download PDF (M√©todo Selenium): {file_name}")
        print(f"  Processando: {file_name[:60]}...")
        
        file_metadata = service.files().get(fileId=file_id, fields='webViewLink').execute()
        view_url = file_metadata.get('webViewLink')
        if not view_url:
            return False

        options = ChromeOptions()
        options.add_argument('--headless=new')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
        options.add_argument('--log-level=3')
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--force-device-scale-factor=2')
        
        os.environ['WDM_LOG_LEVEL'] = '0'
        
        service_obj = Service(ChromeDriverManager().install())
        service_obj.log_path = os.devnull if os.name != 'nt' else 'NUL'
        
        driver = webdriver.Chrome(service=service_obj, options=options)
        driver.get(view_url)
        
        print("    Aguardando carregamento...")
        time.sleep(12)
        
        # Scroll e captura (c√≥digo original simplificado)
        body = driver.find_element("tag name", "body")
        for i in range(50):
            body.send_keys(Keys.PAGE_DOWN)
            time.sleep(0.2)
        
        time.sleep(5)
        
        page_images = []
        all_pages = driver.execute_script("""
            let imgs = Array.from(document.getElementsByTagName('img'));
            let pageImgs = imgs.filter(img => 
                img.src.startsWith('blob:') && img.naturalHeight > 100
            );
            let unique = new Map();
            pageImgs.forEach(img => unique.set(img.src, img));
            return unique.size;
        """)
        
        if all_pages == 0:
            driver.quit()
            return False
        
        print(f"    Capturando {all_pages} p√°ginas...")
        
        for page_idx in range(all_pages):
            try:
                page_data = driver.execute_script(f"""
                    let imgs = Array.from(document.getElementsByTagName('img'));
                    let pageImgs = imgs.filter(img => img.src.startsWith('blob:'));
                    let unique = new Map();
                    pageImgs.forEach(img => unique.set(img.src, img));
                    let pagesArray = Array.from(unique.values());
                    
                    if (pagesArray[{page_idx}]) {{
                        let img = pagesArray[{page_idx}];
                        img.scrollIntoView({{block: 'center'}});
                        let canvas = document.createElement('canvas');
                        canvas.width = img.naturalWidth;
                        canvas.height = img.naturalHeight;
                        canvas.getContext('2d').drawImage(img, 0, 0);
                        return canvas.toDataURL('image/png');
                    }}
                    return null;
                """)
                
                if page_data:
                    import base64
                    img_data = base64.b64decode(page_data.split(',')[1])
                    page_images.append(Image.open(io.BytesIO(img_data)))
                    
                time.sleep(0.3)
            except Exception as e:
                logging.warning(f"Erro ao capturar p√°gina {page_idx + 1}: {e}")
        
        driver.quit()
        
        if not page_images:
            return False
        
        print(f"    Gerando PDF ({len(page_images)} p√°ginas)...")
        
        if len(page_images) == 1:
            page_images[0].save(save_path, 'PDF', resolution=100.0, quality=95)
        else:
            page_images[0].save(save_path, 'PDF', resolution=100.0, save_all=True,
                              append_images=page_images[1:], quality=95)
        
        file_size = os.path.getsize(save_path)
        print(f"    ‚úì Completo: {file_size / 1024 / 1024:.2f} MB ({len(page_images)} p√°ginas)")
        logging.info(f"SUCESSO (PDF): '{file_name}' ({len(page_images)} p√°ginas)")
        
        return True
        
    except Exception as e:
        logging.error(f"Erro Selenium: {type(e).__name__}: {e}")
        if driver:
            try:
                driver.quit()
            except:
                pass
        return False


# ============================================================================
# FUN√á√ÉO PRINCIPAL DE INTERFACE
# ============================================================================

def download_view_only_pdf(service, file_id: str, save_path: str, 
                          temp_download_dir: str) -> bool:
    """
    Fun√ß√£o principal para download de PDFs view-only.
    Usa automaticamente o melhor m√©todo dispon√≠vel (Playwright > Selenium).
    """
    if PLAYWRIGHT_AVAILABLE:
        return asyncio.run(
            download_view_only_pdf_playwright(service, file_id, save_path, temp_download_dir)
        )
    elif SELENIUM_AVAILABLE:
        logging.warning("Playwright n√£o dispon√≠vel, usando fallback Selenium (menos eficiente)")
        return download_view_only_pdf_selenium(service, file_id, save_path, temp_download_dir)
    else:
        logging.error("Nenhuma ferramenta de automa√ß√£o dispon√≠vel. "
                     "Instale Playwright (recomendado) ou Selenium.")
        return False